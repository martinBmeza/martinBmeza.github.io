<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Martin Bernardo Meza | Curriculum | LinkedIn | GitHub I&#39;m a Sound Engineering advanced student, currently finishing my final thesis work named &quot;Speech Dereverberation using Deep Learning algorithms&quot;. Furthermore, I currently have a position as teaching fellow in Signal and Systems subject at Universidad Nacional Tres de Febrero, where I mainly work with audio signal processes and Python programming. I&#39;m interested in the application of deep learning techniques to audio signal processing and analysis. More precisely, I especially like to work in applications related to speech signals.</title>
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Martin Bernardo Meza" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Curriculum | LinkedIn | GitHub I&#39;m a Sound Engineering advanced student, currently finishing my final thesis work named &quot;Speech Dereverberation using Deep Learning algorithms&quot;. Furthermore, I currently have a position as teaching fellow in Signal and Systems subject at Universidad Nacional Tres de Febrero, where I mainly work with audio signal processes and Python programming. I&#39;m interested in the application of deep learning techniques to audio signal processing and analysis. More precisely, I especially like to work in applications related to speech signals." />
<meta property="og:description" content="Curriculum | LinkedIn | GitHub I&#39;m a Sound Engineering advanced student, currently finishing my final thesis work named &quot;Speech Dereverberation using Deep Learning algorithms&quot;. Furthermore, I currently have a position as teaching fellow in Signal and Systems subject at Universidad Nacional Tres de Febrero, where I mainly work with audio signal processes and Python programming. I&#39;m interested in the application of deep learning techniques to audio signal processing and analysis. More precisely, I especially like to work in applications related to speech signals." />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="Martin Bernardo Meza" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Martin Bernardo Meza" />
<script type="application/ld+json">
{"@type":"WebSite","url":"http://localhost:4000/","name":"Martin Bernardo Meza","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/logo.png"}},"headline":"Martin Bernardo Meza","description":"Curriculum | LinkedIn | GitHub I&#39;m a Sound Engineering advanced student, currently finishing my final thesis work named &quot;Speech Dereverberation using Deep Learning algorithms&quot;. Furthermore, I currently have a position as teaching fellow in Signal and Systems subject at Universidad Nacional Tres de Febrero, where I mainly work with audio signal processes and Python programming. I&#39;m interested in the application of deep learning techniques to audio signal processing and analysis. More precisely, I especially like to work in applications related to speech signals.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'G-M58VBTTBEQ', 'auto');
    ga('send', 'pageview');
  </script>



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">Martin Bernardo Meza</a></h1>

        
          <img src="/assets/img/logo.png" alt="Logo" />
        

        <p><p align="center"> <a href="pdf/resume.pdf">Curriculum</a> | <a href="https://www.linkedin.com/in/martin-bernardo-meza/">LinkedIn</a> | <a href="https://github.com/martinBmeza">GitHub</a> </p>
<p align="justify"> I'm a Sound Engineering advanced student, currently finishing my final thesis work named "Speech Dereverberation using Deep Learning algorithms". Furthermore, I currently have a position as teaching fellow in Signal and Systems subject at Universidad Nacional Tres de Febrero, where I mainly work with audio signal processes and Python programming.
<br><br> I'm interested in the application of deep learning techniques to audio signal processing and analysis. More precisely, I especially like to work in applications related to speech signals.    </p></p>

        


        
      </header>
      <section>

      <h1 id="portfolio">Portfolio</h1>

<h2 id="speech-dereverberation-using-convolutional-neural-networks-cnn">Speech Dereverberation using Convolutional Neural Networks (CNN)</h2>
<p>In this research, speech dereverberation based on deep learning algorithms is studied. A convolutional neural network model called autoencoder with skip connections is implemented, following the current state of the art. The neural network is developed to estimate amplitude masks that perform speech dereverberation in the short-time Fourier transform domain. One of the issues of this particular task is the lack of a large training dataset, so generation and augmentation techniques were analyzed, evaluating the impact on model’s performance. In addition, ways to handle phase information and data during training were studied.</p>

<p><img src="/images/modelo_red.png" alt="Estructura Implementada" /></p>

<p>The results show that the generation and augmentation techniques allow to improve the model’s performance. Moreover, sorting the training data from smallest to largest reverberation time results in better evaluation metrics. Finally, improvements for the implemented model and future lines of research were proposed.</p>

<p>This research was the final thesis work developed to achieve the Sound Engineer degree in Universidad Nacional de Tres de Febrero, and has been finished in November 2021. Full document is available in this <a href="pdf/Meza_Dereverberación del habla a partir de algoritmos de aprendizaje profundo.pdf">link</a>.</p>

<p align="center">
<a href="https://martinbmeza.github.io/deep-dereverb/">Keep Reading</a> |
<a href="https://github.com/martinBmeza/deep-dereverb">See GitHub Repo</a>
</p>

<h2 id="analysis-and-augmentation-of-room-impulse-responses">Analysis and Augmentation of Room Impulse Responses</h2>
<p>Room Impulse Response databases are usually expensive and time-consuming to collect. Moreover, if we analyze some acoustics parameters like reverberation time (RT) and direct-to-reverberant ratio (DRR) in the database, in general it is difficult to achieve a good variation of these parameters. In other words, small size datasets bring issues in some applications like training deep learning models. However, some studies have proposed several techniques to perform RIR augmentation, having control over certain acoustic parameters like the ones mentioned above, RT and DRR. Here, these techniques to parametrically control the RT and DRR where implemented generating a useful tool that allows expand a small dataset of RIR into a balanced dataset order of magnitude larger.</p>

<p><img src="/images/tr_aug.png" alt="Aumentacion" /></p>

<p>Also, this work provide some python scripts to perform basic acoustic analysis of audio signals, and more precisely, of RIRs, such as band-filtering, reverberation time calculation, direct-to-reverberant ratio calculation, and implementations of noise floor estimation methods.</p>

<p><img src="/images/banco_filtros.png" alt="Filtros" /></p>

<p align="center">
<a href="pdf/rir_aug.pdf">Keep Reading</a> |
<a href="https://github.com/martinBmeza/rir_analysis">See GitHub Repo</a>
</p>

<!---# Audio Denoising Framework 
La idea de este projecto es servir como un punto de partida para explicar el uso de ciertas herramientas referidas a la inteligencia artificial y el uso de redes neuronales. Se plantea una aplicacion de ejemplo que consiste en elimiar ruido blanco presente en un tono puro. Se crean datos de partida, se arma un modelo de red neuronal convolucional tipo auto-encoder, se compila y entrena este modelo y se lo utiliza para hacer predicciones. De esta manera se recorren todas las instancias que entran en juego a la hora de desarrollar un projecto de esta indole. Las librerias que se utilizan son:
+ Tensorflow
+ Librosa
+ Numpy -->


      </section>
      <footer>
        

      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
  </body>
</html>
